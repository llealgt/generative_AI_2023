{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e912341",
   "metadata": {},
   "source": [
    "# Basic GAN\n",
    "\n",
    "Just a simple good old original GAN for me to refresh my memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ae4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52f64529",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'libc10_cuda.so: cannot open shared object file: No such file or directory'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import make_grid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503ef5d",
   "metadata": {},
   "source": [
    "## Utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5bf4271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization function\n",
    "\n",
    "def show_images(tensor,channels=1,size=(28,28),num=16):\n",
    "    \"\"\"\n",
    "    tensor = 128 x 784\n",
    "    \"\"\"\n",
    "    data = tensor.detach().cpu().view(-1,channels,*size) #128x1x28x28\n",
    "    \n",
    "    grid_original = make_grid(data[:num],nrow=int(np.sqrt(num))) # num x 1 x 28 x 28\n",
    "    grid = grid_original.permute(1, 2, 0) # num x 28 x 28 x 1\n",
    "    \n",
    "    plt.imshow(grid)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0b0ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_tranform():\n",
    "    \n",
    "    transform = transforms.ToTensor()\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07bb228",
   "metadata": {},
   "source": [
    "## Parameters and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e0b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup main params and hyper-params\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "EPOCHS = 1000\n",
    "LEARNING_RATE = 0.00001\n",
    "BATCH_SIZE = 256\n",
    "Z_DIM = 64\n",
    "\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "current_step = 0\n",
    "show_every = 1000\n",
    "show_ims_every = 1000\n",
    "\n",
    "mean_generator_loss = 0\n",
    "mean_discriminator_loss = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfebeef6",
   "metadata": {},
   "source": [
    "## Download data and prepare loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfab09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(MNIST(\".\", download = True, \n",
    "                               transform = preprocessing_tranform()),\n",
    "                         shuffle=True,batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c30fbf",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cfbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genBlock(input_dim, output_dim):\n",
    "    \"\"\"\n",
    "        input_dim = input size\n",
    "        output_dim = output_size\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.BatchNorm1d(output_dim),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb210bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, z_dim=64, image_dim = 784, hidden_dim = 128):\n",
    "        \"\"\"\n",
    "        z_dim = size of the random input vector\n",
    "        image_dim = size of the flattened images\n",
    "        hidden_dim = base size of the hidden layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gen = nn.Sequential(\n",
    "            genBlock(z_dim, hidden_dim), #z_dim x hidden_dim,\n",
    "            genBlock(hidden_dim, hidden_dim*2),\n",
    "            genBlock(hidden_dim*2, hidden_dim*4),\n",
    "            genBlock(hidden_dim*4, hidden_dim*8),\n",
    "            nn.Linear(hidden_dim*8, image_dim),\n",
    "            \n",
    "            # make the output between 0 and 1 (black and white images)\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, noise):\n",
    "        \"\"\"\n",
    "        noise = random noise vector\n",
    "        \"\"\"\n",
    "        return self.gen(noise)\n",
    "    \n",
    "def generate_noise(number, z_dim):\n",
    "    \"\"\"\n",
    "    number = number of random vectors\n",
    "    z_dim = size of every random_vector\n",
    "    \"\"\"\n",
    "    return torch.randn(number, z_dim).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae5e8946",
   "metadata": {},
   "source": [
    "# D@taOps123456789Paco++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8faf345",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9415ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discBlock(input_dim, output_dim):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, output_dim),\n",
    "        nn.LeakyReLU(0.2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47a9cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim = 784,hidden_dim=256):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.disc = nn.Sequential(\n",
    "            discBlock(input_dim, hidden_dim*4), \n",
    "            discBlock(hidden_dim*4, hidden_dim*2), \n",
    "            discBlock(hidden_dim*2, hidden_dim),\n",
    "            # 1 output that classifies an input image as real or fake\n",
    "            nn.Linear(hidden_dim, 1), # input_dim x 1\n",
    "        )\n",
    "        \n",
    "    def forward(self, image):\n",
    "        \"\"\"\n",
    "        image = input image to be classified as real or fake\n",
    "        \"\"\"\n",
    "        return self.disc(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04ae44",
   "metadata": {},
   "source": [
    "\n",
    "## Define models and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74dab6c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mZ_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m generator_optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(generator\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m LEARNING_RATE)\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python310_tf29/lib/python3.10/site-packages/torch/cuda/__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "generator = Generator(z_dim=Z_DIM,hidden_dim=256).to(device)\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34269b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29753297",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(hidden_dim=256).to(device)\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6b30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49d497b",
   "metadata": {},
   "source": [
    "## Check everything is correct\n",
    "* Dimensions\n",
    "* Initial generator output(should be random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69daf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(data_loader))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4354ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = generate_noise(BATCH_SIZE,Z_DIM)\n",
    "fake_images = generator(noise)\n",
    "\n",
    "show_images(fake_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc6bf22",
   "metadata": {},
   "source": [
    "Output is pure noise as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de12e3c2",
   "metadata": {},
   "source": [
    "## Defining loss functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6af170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss\n",
    "def generator_forward_and_loss_calculate(loss_function, generator, discriminator, number, z_dim):\n",
    "    \"\"\"Takes random noise and generates fake images, then calculate loss for those generated ims\"\"\"\n",
    "    \n",
    "    noise = generate_noise(number, z_dim)\n",
    "    fake_images = generator(noise)\n",
    "    # pass fake images and get discriminator score(probability  of being real)\n",
    "    ## we want to maximize this score\n",
    "    generated_ims_pred = discriminator(fake_images)\n",
    "    \n",
    "    #calcualate the generator loss by comparing scores to 1s(1s means real)\n",
    "    targets = torch.ones_like(generated_ims_pred)\n",
    "    generator_loss = loss_function(generated_ims_pred, targets)\n",
    "    \n",
    "    return generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894e6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator loss\n",
    "def discriminator_forward_and_loss_calculate(loss_function, generator, discriminator, number, \n",
    "                                             real_images,z_dim):\n",
    "    \"\"\"takes real images and random noise to forward through the discriminator and calculate its loss\"\"\"\n",
    "    \n",
    "    real_ims_pred = discriminator(real_images)\n",
    "    \n",
    "    noise = generate_noise(number, z_dim)\n",
    "    fake_images = generator(noise)\n",
    "    # pass fake images and get discriminator score(probability  of being real)\n",
    "    ## we want to minimize this score\n",
    "    generated_ims_pred = discriminator(fake_images.detach())\n",
    "    \n",
    "    #calculate the discriminator loss for fake images by comparing scores to 0s(0s means fake)\n",
    "    discriminator_fake_targets = torch.zeros_like(generated_ims_pred)\n",
    "    disc_fake_loss = loss_function(generated_ims_pred, discriminator_fake_targets)\n",
    "    \n",
    "    # calculate discriminator loss for real images by comparing scores to 1s(1s means real)\n",
    "    discriminator_real_targets = torch.ones_like(real_ims_pred)\n",
    "    disc_real_loss = loss_function(real_ims_pred, discriminator_real_targets)\n",
    "    \n",
    "    # total loss is average between real and fake losses\n",
    "    total_loss = (disc_fake_loss + disc_real_loss)/2\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56849ca8",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ece7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = data_loader.dataset.data.data.size()[0]/BATCH_SIZE\n",
    "show_ims_every = int(steps_per_epoch)*10 # to show every k epochs, this is temporary for overwriting specifying the num of steps\n",
    "print(f\"{steps_per_epoch} steps with {BATCH_SIZE} per step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0344ce8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_losses = []\n",
    "gen_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for real_ims, _ in tqdm(data_loader):\n",
    "        ### discriminator\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        \n",
    "        current_batch_size = len(real_ims) #last step contains less images\n",
    "        real_ims = real_ims.view(current_batch_size, -1)\n",
    "        real_ims = real_ims.to(device)\n",
    "        \n",
    "        discriminator_loss = discriminator_forward_and_loss_calculate(loss_function, generator, discriminator,\n",
    "                                        current_batch_size, real_ims, Z_DIM\n",
    "                                                                     )\n",
    "        \n",
    "        discriminator_loss.backward(retain_graph = True)\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        ### generator\n",
    "        generator_optimizer.zero_grad()\n",
    "        generator_loss = generator_forward_and_loss_calculate(loss_function, generator, discriminator,\n",
    "                                        current_batch_size, Z_DIM                     \n",
    "                                                            )\n",
    "        generator_loss.backward(retain_graph = True)\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "        ### output and feedback\n",
    "        mean_disc_loss = discriminator_loss.item()\n",
    "        mean_gen_loss = generator_loss.item()\n",
    "        \n",
    "        disc_losses.append(mean_disc_loss)\n",
    "        gen_losses.append(mean_generator_loss)\n",
    "        \n",
    "        if current_step > 0 and current_step % show_ims_every == 0:\n",
    "            fake_noise = generate_noise(current_batch_size, Z_DIM)\n",
    "            fake_ims = generator(fake_noise)\n",
    "            \n",
    "            plt.plot(gen_losses)\n",
    "            plt.plot(disc_losses)\n",
    "            \n",
    "            show_images(fake_ims)\n",
    "            show_images(real_ims)\n",
    "            \n",
    "            plt.show()\n",
    "            \n",
    "        if current_step > 0 and current_step % show_every == 0:            \n",
    "            print(f\"{epoch}: step {current_step}, gen loss:{mean_gen_loss}, disc loss: {mean_disc_loss}\")\n",
    "            \n",
    "        current_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923b7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21af288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
